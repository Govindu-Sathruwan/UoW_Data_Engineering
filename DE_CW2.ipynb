{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Mqv9_0psCXmWUwElTSsbULkXgi3EEqQy","authorship_tag":"ABX9TyMpa9ApLTre0XJrgrJWVSoF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# import necessary packages\n","import cv2\n","import pandas as pd\n","import os\n","import json\n","import numpy as np\n","from skimage import feature\n","from matplotlib import pyplot as plt\n","from matplotlib import image as mpimg"],"metadata":{"id":"1ZxmYCrdhbe8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a function to rename the files\n","def rename_images(directory, prefix=\"image_\", start_number=1, extension=\".jpg\"):\n","  \"\"\"Renames images in the directory with a naming convention.\"\"\"\n","  for i, filename in enumerate(os.listdir(directory)):\n","    if filename.endswith(extension):\n","      new_filename = f\"{prefix}{start_number + i:03}{extension}\"\n","      os.rename(os.path.join(directory, filename),\n","                os.path.join(directory, new_filename))"],"metadata":{"id":"-BkbrKzmfHL6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the created function and rename the images\n","image_directory = \"/content/drive/MyDrive/DE_CW2/Original_Images\"\n","rename_images(image_directory)"],"metadata":{"id":"7Q2W9IyXfUx2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a function to resize images to 500x500\n","def resize_images_cv2(input_dir, output_dir, size=(500, 500)):\n","    \"\"\"Resizes all images in th directory to 500X500 size using cv2 and save them to a new directory.\"\"\"\n","    for filename in os.listdir(input_dir):\n","        if filename.endswith(('.jpg')):\n","            input_filepath = os.path.join(input_dir, filename)\n","            output_filepath = os.path.join(output_dir, filename)\n","\n","            img = cv2.imread(input_filepath)\n","            resized_img = cv2.resize(img, size)\n","            cv2.imwrite(output_filepath, resized_img)"],"metadata":{"id":"Ryc53ICnhKVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Using the created function to resize the images\n","input_directory = \"/content/drive/MyDrive/DE_CW2/Original_Images\"\n","output_directory = \"/content/drive/MyDrive/DE_CW2/Processed_images\"\n","resize_images_cv2(input_directory, output_directory)"],"metadata":{"id":"Bmkfo7coj0c5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function to reduce noise in the images\n","def apply_gaussian_blur(image_path, kernel_size=(5, 5), sigma=0):\n","  \"\"\"Applies Gaussian blur to an image to reduce noise in the resized images.\"\"\"\n","  img = cv2.imread(image_path)\n","  blurred_img = cv2.GaussianBlur(img, kernel_size, sigma)\n","  cv2.imwrite(image_path, blurred_img)"],"metadata":{"id":"n3lA6YoBoo-0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Applyig the function to reduce the noise in images\n","for filename in os.listdir('/content/drive/MyDrive/DE_CW2/Processed_images'):\n","    if filename.endswith(('.jpg')):\n","        image_path = os.path.join('/content/drive/MyDrive/DE_CW2/Processed_images', filename)\n","        apply_gaussian_blur(image_path)"],"metadata":{"id":"9lVQyAbDqIjF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function to rotate selected images 90 degrees clockwise\n","def rotate_and_replace_images(directory, image_names, angle=cv2.ROTATE_90_CLOCKWISE):\n","  \"\"\"Rotates specified images using cv2.rotate and replaces the originals.\"\"\"\n","  for image_name in image_names:\n","    image_path = os.path.join(directory, image_name)\n","    img = cv2.imread(image_path)\n","    rotated_img = cv2.rotate(img, angle)\n","    cv2.imwrite(image_path, rotated_img)"],"metadata":{"id":"qg6GTzlIgAW5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# using the created function, rotate selected images 90 degrees clockwise\n","directory = \"/content/drive/MyDrive/DE_CW2/Processed_images\"\n","images_to_rotate = [\"image_040.jpg\", \"image_044.jpg\"]\n","\n","rotate_and_replace_images(directory, images_to_rotate)"],"metadata":{"id":"B-Zr36CMkuLF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the Excel files with\n","df = pd.read_excel(\"/content/drive/MyDrive/DE_CW2/Image annotations.xlsx\")\n","\n","# Save to JSON\n","df.to_json(\"/content/drive/MyDrive/DE_CW2/Image annotations.json\", orient=\"records\", indent=4)\n"],"metadata":{"id":"VrCBvl0Dx2nq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from skimage.feature import graycomatrix, graycoprops\n","from skimage.measure import label, regionprops\n","\n","def extract_features(image_path):\n","  \"\"\"Extracts color, texture, and shape features from an image.\"\"\"\n","  # Read the image\n","  img = cv2.imread(image_path)\n","\n","  # Colour Features\n","  # Mean Intensity\n","  mean_intensity = np.mean(img)\n","  # Norm Intensity\n","  norm_intensity = mean_intensity / 255.0\n","\n","  # 3 Color Moments (mean, std, skewness)\n","  mean_color = np.mean(img, axis=(0, 1))\n","  std_color = np.std(img, axis=(0, 1))\n","  skewness_color = np.mean(((img - mean_color) / std_color)**3, axis=(0, 1))\n","\n"," # Collect all the colour features together\n","  colour_features = {\n","      'mean_intensity':mean_intensity,\n","      'norm_intensity':norm_intensity,\n","      'mean_color':mean_color.tolist(),\n","      'std_color':std_color.tolist(),\n","      'skewness_color':skewness_color.tolist()\n","  }\n","  color_moments = np.concatenate([mean_color, std_color, skewness_color])\n","\n","  # Texture Features (GLCM)\n","  gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","  glcm = graycomatrix(gray_img, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256, symmetric=True, normed=True)\n","  texture_features = np.array([\n","      graycoprops(glcm, 'contrast')[0, 0],\n","      graycoprops(glcm, 'dissimilarity')[0, 0],\n","      graycoprops(glcm, 'homogeneity')[0, 0],\n","      graycoprops(glcm, 'energy')[0, 0],\n","      graycoprops(glcm, 'correlation')[0, 0],\n","      graycoprops(glcm, 'ASM')[0, 0]\n","  ])\n","\n","  # Shape Features\n","  # Convert to grayscale and threshold\n","  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","  ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","\n","  # Find contours\n","  contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","  # Get largest contour\n","  largest_contour = max(contours, key=cv2.contourArea)\n","\n","  # Calculate shape features\n","  area = cv2.contourArea(largest_contour)\n","  perimeter = cv2.arcLength(largest_contour, True)\n","  M = cv2.moments(largest_contour)\n","  if M[\"m00\"] != 0:\n","    cx = int(M[\"m10\"] / M[\"m00\"])\n","    cy = int(M[\"m01\"] / M[\"m00\"])\n","    centroid = (cx, cy)\n","  else:\n","    centroid = (0, 0)  # Assign (0, 0) if the moment is zero\n","  x, y, w, h = cv2.boundingRect(largest_contour)\n","  bounding_box = (x, y, w, h)\n","\n","  shape_features = {\n","      'area': area,\n","      'perimeter': perimeter,\n","      'centroid': centroid,\n","      'bounding_box': bounding_box\n","  }\n","  # Store features in a dictionary\n","  features = {\n","      'colour_features': colour_features,\n","      'texture_features': texture_features.tolist(),\n","      'shape_features': shape_features\n","  }\n","\n","  return features\n"],"metadata":{"id":"eb5GJkB17nPj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract features of all images and save to JSON\n","image_directory = '/content/drive/MyDrive/DE_CW2/Processed_images'\n","all_features = []\n","\n","for filename in os.listdir(image_directory):\n","  if filename.endswith(('.jpg')):\n","    image_path = os.path.join(image_directory, filename)\n","    features = extract_features(image_path)\n","    ordered_features = {\n","            'filename': filename,  # to get the image name first\n","            'colour_features': features['colour_features'],\n","            'texture_features': features['texture_features'],\n","            'shape_features': features['shape_features']\n","        }\n","    all_features.append(ordered_features)\n","\n","# Save to JSON\n","with open('/content/drive/MyDrive/DE_CW2/Feature_Extraction.json', 'w') as f:\n","  json.dump(all_features, f, indent=4)"],"metadata":{"id":"5mzCIQxxPgoe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mongodb+srv://Govindu:2004GOVIss@dataengcw.zehi4.mongodb.net/?retryWrites=true&w=majority&appName=DataEngCW"],"metadata":{"id":"PxyvDvh1nZ_E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install pymongo\n","!pip install pymongo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suhyggYzo8sD","executionInfo":{"status":"ok","timestamp":1732898237705,"user_tz":-330,"elapsed":8056,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"e13910ae-93ad-4735-ab7b-3c46baac5fbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pymongo\n","  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n","  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dnspython, pymongo\n","Successfully installed dnspython-2.7.0 pymongo-4.10.1\n"]}]},{"cell_type":"code","source":["from pymongo import MongoClient\n","import gridfs"],"metadata":{"id":"i-LMq0I7pQ_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install \"pymongo[srv]\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-r4M2kXMef8","executionInfo":{"status":"ok","timestamp":1732898247583,"user_tz":-330,"elapsed":6497,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"dda01453-9162-409a-fc23-7376812cb0e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.10/dist-packages (4.10.1)\n","\u001b[33mWARNING: pymongo 4.10.1 does not provide the extra 'srv'\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo[srv]) (2.7.0)\n"]}]},{"cell_type":"code","source":["Image_connection = MongoClient(\"mongodb+srv://Govindu:2004GOVIss@dataengcw.zehi4.mongodb.net/?retryWrites=true&w=majority&appName=DataEngCW\")"],"metadata":{"id":"PjeI6xl4AqXT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["db = Image_connection[\"CBIR\"]"],"metadata":{"id":"OpN-2UTcq_px"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","  print(db.list_collection_names())\n","except Exception as e:\n","    print(f\"Connection Failed: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"quCFK6CYpf4G","executionInfo":{"status":"ok","timestamp":1732898253961,"user_tz":-330,"elapsed":1295,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"222ab77b-b23e-46d5-c7f0-5e4e063573c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['processed_images', 'image_annotations', 'features_extracted']\n"]}]},{"cell_type":"code","source":["image_annotations_collection = db[\"image_annotations\"]\n","\n","# Load JSON metadata file\n","with open('/content/drive/MyDrive/DE_CW2/Image annotations.json') as file:\n","    image_data = json.load(file)\n","\n","# Insert data into MongoDB collection\n","if isinstance(image_data, list):\n","    image_annotations_collection.insert_many(image_data)  # For a list of documents\n","else:\n","    image_annotations_collection.insert_one(image_data)  # For a single document"],"metadata":{"id":"-3BiDd7kpmr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["extracted_features_collection = db[\"features_extracted\"]\n","\n","# Load JSON metadata file\n","with open('/content/drive/MyDrive/DE_CW2/Feature_Extraction.json') as file:\n","    image_data = json.load(file)\n","\n","# Insert data into MongoDB collection\n","if isinstance(image_data, list):\n","    extracted_features_collection.insert_many(image_data)  # For a list of documents\n","else:\n","    extracted_features_collection.insert_one(image_data)  # For a single document"],"metadata":{"id":"IBZ7gP4PssAD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from bson import Binary\n","\n","processed_images_collection = db[\"processed_images\"]\n","\n","image_folder_path = '/content/drive/MyDrive/DE_CW2/Processed_images'\n","\n","for filename in os.listdir(image_folder_path):\n","    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n","        with open(os.path.join(image_folder_path, filename), \"rb\") as image_file:\n","            binary_image = Binary(image_file.read())\n","            image_doc = {\n","                \"filename\": filename,\n","                \"image_data\": binary_image\n","            }\n","            processed_images_collection.insert_one(image_doc)"],"metadata":{"id":"MRIWfMI0vEDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example query to find an image by filename\n","query = {'filename': \"image_012.jpg\"}\n","image_document = processed_images_collection.find_one(query)\n","\n","if image_document:\n","    print(\"Image found:\", image_document[\"filename\"])\n","else:\n","    print(\"No image found with the specified criteria.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9uvo3RgvtdY","executionInfo":{"status":"ok","timestamp":1732898336604,"user_tz":-330,"elapsed":1029,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"0df4deb1-e579-4fa6-f3b9-7ba6d05f117e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image found: image_012.jpg\n"]}]},{"cell_type":"markdown","source":["Question 2"],"metadata":{"id":"6ZldqTpaK0VI"}},{"cell_type":"code","source":["# import necessary packages\n","import cv2\n","import pandas as pd\n","import os\n","import json\n","import numpy as np\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","import string"],"metadata":{"id":"MzGN49mVK4iv","executionInfo":{"status":"ok","timestamp":1733290204522,"user_tz":-330,"elapsed":6588,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Download stopwords and punkt tokenizer\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('punkt_tab')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PWf5Hf-NSx7a","executionInfo":{"status":"ok","timestamp":1733232931385,"user_tz":-330,"elapsed":1018,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"decc074d-478a-4a76-a195-2fe6ae2f57a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["CSV_file_path = '/content/drive/MyDrive/DE_CW2/movie.csv'\n","df = pd.read_csv(CSV_file_path)\n","\n","df_sample = df.sample(n=65, random_state=42)\n","df_sample = df_sample.reset_index(drop=True)"],"metadata":{"id":"cHuTIam2L5JT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df_sample.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_cgMhhMNCqZ","executionInfo":{"status":"ok","timestamp":1733232943591,"user_tz":-330,"elapsed":2,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"f0f3fb15-5cbf-459b-d65d-b97e9ff3a05d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['text', 'label'], dtype='object')\n"]}]},{"cell_type":"code","source":["original_text_directory = '/content/drive/MyDrive/DE_CW2/Original_Text'\n","\n","# Iterate through the subset DataFrame and save each row as a text file\n","for i, row in df_sample.iterrows():\n","    text = row['text']\n","\n","    # Create a filename for each text file\n","    filename = f\"Review_{i + 1:03}.txt\"\n","    file_path = os.path.join(original_text_directory, filename)\n","\n","    # Write the text to the file\n","    with open(file_path, 'w', encoding='utf-8') as f:\n","        f.write(text)\n","\n","    print(f\"Saved {filename}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oF0RZ7D5NH4p","executionInfo":{"status":"ok","timestamp":1733232962997,"user_tz":-330,"elapsed":18089,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"6c7fbcf9-a2c6-41cb-cd33-2f7d914840a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved Review_001.txt\n","Saved Review_002.txt\n","Saved Review_003.txt\n","Saved Review_004.txt\n","Saved Review_005.txt\n","Saved Review_006.txt\n","Saved Review_007.txt\n","Saved Review_008.txt\n","Saved Review_009.txt\n","Saved Review_010.txt\n","Saved Review_011.txt\n","Saved Review_012.txt\n","Saved Review_013.txt\n","Saved Review_014.txt\n","Saved Review_015.txt\n","Saved Review_016.txt\n","Saved Review_017.txt\n","Saved Review_018.txt\n","Saved Review_019.txt\n","Saved Review_020.txt\n","Saved Review_021.txt\n","Saved Review_022.txt\n","Saved Review_023.txt\n","Saved Review_024.txt\n","Saved Review_025.txt\n","Saved Review_026.txt\n","Saved Review_027.txt\n","Saved Review_028.txt\n","Saved Review_029.txt\n","Saved Review_030.txt\n","Saved Review_031.txt\n","Saved Review_032.txt\n","Saved Review_033.txt\n","Saved Review_034.txt\n","Saved Review_035.txt\n","Saved Review_036.txt\n","Saved Review_037.txt\n","Saved Review_038.txt\n","Saved Review_039.txt\n","Saved Review_040.txt\n","Saved Review_041.txt\n","Saved Review_042.txt\n","Saved Review_043.txt\n","Saved Review_044.txt\n","Saved Review_045.txt\n","Saved Review_046.txt\n","Saved Review_047.txt\n","Saved Review_048.txt\n","Saved Review_049.txt\n","Saved Review_050.txt\n","Saved Review_051.txt\n","Saved Review_052.txt\n","Saved Review_053.txt\n","Saved Review_054.txt\n","Saved Review_055.txt\n","Saved Review_056.txt\n","Saved Review_057.txt\n","Saved Review_058.txt\n","Saved Review_059.txt\n","Saved Review_060.txt\n","Saved Review_061.txt\n","Saved Review_062.txt\n","Saved Review_063.txt\n","Saved Review_064.txt\n","Saved Review_065.txt\n"]}]},{"cell_type":"code","source":["# Define a function to conver the text files to lowercase\n","def convert_to_lowercase(direc_in,direc_out):\n","  for filename in os.listdir(direc_in):\n","    if filename.endswith('.txt'):\n","       output_file_path = os.path.join(direc_out, filename)\n","       input_file_path = os.path.join(direc_in, filename)\n","\n","       with open(input_file_path, 'r', encoding='utf-8') as f:\n","           text = f.read()\n","       lowercase_text = text.lower()\n","\n","       with open(output_file_path, 'w', encoding='utf-8') as f:\n","           f.write(lowercase_text)\n","    print(f\"Converted {filename} to lowercase.\")"],"metadata":{"id":"mQudfU0tOeZB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["direc_in = '/content/drive/MyDrive/DE_CW2/Original_Text'\n","direc_out = '/content/drive/MyDrive/DE_CW2/Preprocessed_Text'"],"metadata":{"id":"snzKPOcbUod5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the defined function to apply to all the txt files\n","convert_to_lowercase(direc_in,direc_out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a30Y0olJWxoq","executionInfo":{"status":"ok","timestamp":1732975871945,"user_tz":-330,"elapsed":1362,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"a6931e89-1f72-4c3a-e8e3-207f3205a5b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Converted .ipynb_checkpoints to lowercase.\n","Converted Review_001.txt to lowercase.\n","Converted Review_002.txt to lowercase.\n","Converted Review_003.txt to lowercase.\n","Converted Review_004.txt to lowercase.\n","Converted Review_005.txt to lowercase.\n","Converted Review_006.txt to lowercase.\n","Converted Review_007.txt to lowercase.\n","Converted Review_008.txt to lowercase.\n","Converted Review_009.txt to lowercase.\n","Converted Review_010.txt to lowercase.\n","Converted Review_011.txt to lowercase.\n","Converted Review_012.txt to lowercase.\n","Converted Review_013.txt to lowercase.\n","Converted Review_014.txt to lowercase.\n","Converted Review_015.txt to lowercase.\n","Converted Review_016.txt to lowercase.\n","Converted Review_017.txt to lowercase.\n","Converted Review_018.txt to lowercase.\n","Converted Review_019.txt to lowercase.\n","Converted Review_020.txt to lowercase.\n","Converted Review_021.txt to lowercase.\n","Converted Review_022.txt to lowercase.\n","Converted Review_023.txt to lowercase.\n","Converted Review_024.txt to lowercase.\n","Converted Review_025.txt to lowercase.\n","Converted Review_026.txt to lowercase.\n","Converted Review_027.txt to lowercase.\n","Converted Review_028.txt to lowercase.\n","Converted Review_029.txt to lowercase.\n","Converted Review_030.txt to lowercase.\n","Converted Review_031.txt to lowercase.\n","Converted Review_032.txt to lowercase.\n","Converted Review_033.txt to lowercase.\n","Converted Review_034.txt to lowercase.\n","Converted Review_035.txt to lowercase.\n","Converted Review_036.txt to lowercase.\n","Converted Review_037.txt to lowercase.\n","Converted Review_038.txt to lowercase.\n","Converted Review_039.txt to lowercase.\n","Converted Review_040.txt to lowercase.\n","Converted Review_041.txt to lowercase.\n","Converted Review_042.txt to lowercase.\n","Converted Review_043.txt to lowercase.\n","Converted Review_044.txt to lowercase.\n","Converted Review_045.txt to lowercase.\n","Converted Review_046.txt to lowercase.\n","Converted Review_047.txt to lowercase.\n","Converted Review_048.txt to lowercase.\n","Converted Review_049.txt to lowercase.\n","Converted Review_050.txt to lowercase.\n","Converted Review_051.txt to lowercase.\n","Converted Review_052.txt to lowercase.\n","Converted Review_053.txt to lowercase.\n","Converted Review_054.txt to lowercase.\n","Converted Review_055.txt to lowercase.\n","Converted Review_056.txt to lowercase.\n","Converted Review_057.txt to lowercase.\n","Converted Review_058.txt to lowercase.\n","Converted Review_059.txt to lowercase.\n","Converted Review_060.txt to lowercase.\n","Converted Review_061.txt to lowercase.\n","Converted Review_062.txt to lowercase.\n","Converted Review_063.txt to lowercase.\n","Converted Review_064.txt to lowercase.\n","Converted Review_065.txt to lowercase.\n","Converted Review_001.txt to lowercase.\n"]}]},{"cell_type":"code","source":["# Define a function to conver the text files to lowercase\n","def tokenize(directory):\n","  for filename in os.listdir(directory):\n","    if filename.endswith('.txt'):\n","       file_path = os.path.join(directory, filename)\n","\n","       with open(file_path, 'r', encoding='utf-8') as f:\n","           text = f.read()\n","       tokens = word_tokenize(text)\n","\n","       with open(file_path, 'w', encoding='utf-8') as f:\n","        for token in tokens:\n","          f.write(token + '\\n')\n","    print(f\"Tokenized {filename}\")"],"metadata":{"id":"kFIL_nobag1S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["directory = '/content/drive/MyDrive/DE_CW2/Preprocessed_Text'"],"metadata":{"id":"sS5_crMMelNy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the created function to tokenize all the txt files\n","tokenize(directory)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olKzZj1He25F","executionInfo":{"status":"ok","timestamp":1732977072524,"user_tz":-330,"elapsed":1254,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"df0b6d22-10fd-49b1-c0f2-dc02492564f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized Review_001.txt\n","Tokenized Review_002.txt\n","Tokenized Review_003.txt\n","Tokenized Review_004.txt\n","Tokenized Review_005.txt\n","Tokenized Review_006.txt\n","Tokenized Review_007.txt\n","Tokenized Review_008.txt\n","Tokenized Review_009.txt\n","Tokenized Review_010.txt\n","Tokenized Review_011.txt\n","Tokenized Review_012.txt\n","Tokenized Review_013.txt\n","Tokenized Review_014.txt\n","Tokenized Review_015.txt\n","Tokenized Review_016.txt\n","Tokenized Review_017.txt\n","Tokenized Review_018.txt\n","Tokenized Review_019.txt\n","Tokenized Review_020.txt\n","Tokenized Review_021.txt\n","Tokenized Review_022.txt\n","Tokenized Review_023.txt\n","Tokenized Review_024.txt\n","Tokenized Review_025.txt\n","Tokenized Review_026.txt\n","Tokenized Review_027.txt\n","Tokenized Review_028.txt\n","Tokenized Review_029.txt\n","Tokenized Review_030.txt\n","Tokenized Review_031.txt\n","Tokenized Review_032.txt\n","Tokenized Review_033.txt\n","Tokenized Review_034.txt\n","Tokenized Review_035.txt\n","Tokenized Review_036.txt\n","Tokenized Review_037.txt\n","Tokenized Review_038.txt\n","Tokenized Review_039.txt\n","Tokenized Review_040.txt\n","Tokenized Review_041.txt\n","Tokenized Review_042.txt\n","Tokenized Review_043.txt\n","Tokenized Review_044.txt\n","Tokenized Review_045.txt\n","Tokenized Review_046.txt\n","Tokenized Review_047.txt\n","Tokenized Review_048.txt\n","Tokenized Review_049.txt\n","Tokenized Review_050.txt\n","Tokenized Review_051.txt\n","Tokenized Review_052.txt\n","Tokenized Review_053.txt\n","Tokenized Review_054.txt\n","Tokenized Review_055.txt\n","Tokenized Review_056.txt\n","Tokenized Review_057.txt\n","Tokenized Review_058.txt\n","Tokenized Review_059.txt\n","Tokenized Review_060.txt\n","Tokenized Review_061.txt\n","Tokenized Review_062.txt\n","Tokenized Review_063.txt\n","Tokenized Review_064.txt\n","Tokenized Review_065.txt\n"]}]},{"cell_type":"code","source":["# Install scikit-learn\n","!pip install scikit-learn==1.3.1\n","# Import Tfidfvectorization\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DTxjVF1CSpl","executionInfo":{"status":"ok","timestamp":1733233485226,"user_tz":-330,"elapsed":4824,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"f2a349be-684b-4b5d-c32e-3c9f5f2be340"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn==1.3.1 in /usr/local/lib/python3.10/dist-packages (1.3.1)\n","Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.1) (1.26.4)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.1) (1.13.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.1) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.1) (3.5.0)\n"]}]},{"cell_type":"code","source":["preprocessed_text_directory = '/content/drive/MyDrive/DE_CW2/Preprocessed_Text'\n","reviews = []"],"metadata":{"id":"ZNXGnrXv4GxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for filename in os.listdir(preprocessed_text_directory):\n","    if filename.endswith('.txt'):\n","        file_path = os.path.join(preprocessed_text_directory, filename)\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            # Read all lines in the file and join them into a single string\n","            reviews.append(' '.join(f.readlines()))"],"metadata":{"id":"XvcL1nYwDWpZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vectorizer = TfidfVectorizer(min_df=1) # since data set is samll min_df set to 1\n","tfidf_matrix = vectorizer.fit_transform(reviews) # Fit and transform the data"],"metadata":{"id":"_nXJkoy8DqyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the feature names (words)\n","print(vectorizer.get_feature_names_out())\n","\n","# Print the TF-IDF matrix\n","print(tfidf_matrix.toarray())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18magymwD-6e","executionInfo":{"status":"ok","timestamp":1733233550349,"user_tz":-330,"elapsed":2,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"75475b5b-33cc-46b4-e565-677016648d49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['01' '10' '100' ... 'yours' 'yourself' 'zefram']\n","[[0.         0.         0.         ... 0.         0.         0.        ]\n"," [0.         0.03374401 0.         ... 0.         0.         0.        ]\n"," [0.         0.         0.         ... 0.         0.         0.        ]\n"," ...\n"," [0.         0.         0.         ... 0.         0.         0.        ]\n"," [0.         0.         0.         ... 0.         0.         0.        ]\n"," [0.         0.         0.         ... 0.         0.         0.        ]]\n"]}]},{"cell_type":"code","source":["print(tfidf_matrix.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LEvWb8BGCUY","executionInfo":{"status":"ok","timestamp":1733233553211,"user_tz":-330,"elapsed":339,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"30aeff3e-8b1f-48e9-c491-a812099874e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(65, 3195)\n"]}]},{"cell_type":"code","source":["print(tfidf_matrix.sum(axis=1))  # Sum of TF-IDF values per document\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eT4zNSzGWgf","executionInfo":{"status":"ok","timestamp":1733233568426,"user_tz":-330,"elapsed":319,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"bacd640d-701c-4268-b1f6-e89f1f1a6150"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[11.37943704]\n"," [13.79840774]\n"," [ 6.31190333]\n"," [ 7.65557492]\n"," [ 6.9614065 ]\n"," [ 9.85445837]\n"," [ 9.56791406]\n"," [ 8.64618497]\n"," [ 8.01785248]\n"," [ 6.144366  ]\n"," [ 8.77588577]\n"," [ 9.57821376]\n"," [10.53775895]\n"," [ 7.45743341]\n"," [10.77374606]\n"," [ 8.7914998 ]\n"," [ 9.09512887]\n"," [10.44919231]\n"," [ 8.07805341]\n"," [12.08774009]\n"," [11.0781233 ]\n"," [11.94437927]\n"," [ 9.53553264]\n"," [ 8.09523635]\n"," [15.96482221]\n"," [ 5.43457727]\n"," [11.23433387]\n"," [10.04744261]\n"," [10.4208438 ]\n"," [ 9.38788438]\n"," [ 8.64139868]\n"," [ 9.04020381]\n"," [ 9.13620736]\n"," [ 8.52839497]\n"," [ 9.18867236]\n"," [ 8.70314685]\n"," [10.37059432]\n"," [12.97585484]\n"," [ 9.47429022]\n"," [11.42745602]\n"," [ 8.46591606]\n"," [ 9.35559318]\n"," [ 9.6766835 ]\n"," [12.52670105]\n"," [ 7.87186087]\n"," [ 8.02765093]\n"," [ 8.27032446]\n"," [10.10381488]\n"," [10.87515753]\n"," [ 9.73335477]\n"," [ 9.57299508]\n"," [11.98050564]\n"," [11.58917451]\n"," [ 8.94179381]\n"," [ 9.39994342]\n"," [10.16270356]\n"," [10.54037689]\n"," [ 8.13715617]\n"," [ 9.4655374 ]\n"," [ 7.29643754]\n"," [13.19336598]\n"," [11.2500558 ]\n"," [ 6.44259884]\n"," [ 9.268586  ]\n"," [10.85199744]]\n"]}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer"],"metadata":{"id":"KarPo-MnxeTB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vectorizer = CountVectorizer()"],"metadata":{"id":"scwL5Li72a9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vectorizer.fit(reviews)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"AnOINn_d2ez2","executionInfo":{"status":"ok","timestamp":1733234925787,"user_tz":-330,"elapsed":337,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"88e51b53-05a5-4edc-da70-666c9ab2c0dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CountVectorizer()"],"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["bow_matrix = vectorizer.transform(reviews)"],"metadata":{"id":"nk96rUtd2j13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(bow_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YjExUcrz2nkX","executionInfo":{"status":"ok","timestamp":1733234995290,"user_tz":-330,"elapsed":342,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"051ed766-e9ee-478c-b91e-53981de5d503"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  (0, 50)\t1\n","  (0, 65)\t1\n","  (0, 69)\t2\n","  (0, 120)\t5\n","  (0, 141)\t1\n","  (0, 142)\t1\n","  (0, 147)\t1\n","  (0, 150)\t12\n","  (0, 183)\t1\n","  (0, 188)\t4\n","  (0, 194)\t1\n","  (0, 198)\t2\n","  (0, 209)\t2\n","  (0, 259)\t3\n","  (0, 266)\t1\n","  (0, 273)\t1\n","  (0, 288)\t1\n","  (0, 309)\t1\n","  (0, 321)\t1\n","  (0, 345)\t1\n","  (0, 398)\t2\n","  (0, 446)\t1\n","  (0, 467)\t2\n","  (0, 474)\t3\n","  (0, 475)\t1\n","  :\t:\n","  (64, 2721)\t1\n","  (64, 2795)\t1\n","  (64, 2805)\t1\n","  (64, 2809)\t15\n","  (64, 2815)\t1\n","  (64, 2828)\t1\n","  (64, 2833)\t2\n","  (64, 2837)\t1\n","  (64, 2870)\t4\n","  (64, 2990)\t1\n","  (64, 3009)\t1\n","  (64, 3023)\t1\n","  (64, 3064)\t1\n","  (64, 3068)\t2\n","  (64, 3073)\t1\n","  (64, 3077)\t1\n","  (64, 3096)\t1\n","  (64, 3102)\t1\n","  (64, 3113)\t2\n","  (64, 3124)\t2\n","  (64, 3138)\t2\n","  (64, 3165)\t1\n","  (64, 3171)\t1\n","  (64, 3172)\t1\n","  (64, 3186)\t4\n"]}]},{"cell_type":"code","source":["print(\"Feature Names (Words):\", vectorizer.get_feature_names_out())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_DW6xLy4NG5","executionInfo":{"status":"ok","timestamp":1733235381214,"user_tz":-330,"elapsed":329,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"54f11229-6c4f-4b46-ec69-efbfcc798136"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Feature Names (Words): ['01' '10' '100' ... 'yours' 'yourself' 'zefram']\n"]}]},{"cell_type":"code","source":["# Convert the sparse matrix to an array for inspection\n","print(\"Bag of Words Matrix:\\n\", bow_matrix.toarray())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxyCf1Hx4PMj","executionInfo":{"status":"ok","timestamp":1733235379283,"user_tz":-330,"elapsed":355,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"7251abad-88a3-4613-ea8f-16c1a5018738"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Bag of Words Matrix:\n"," [[0 0 0 ... 0 0 0]\n"," [0 1 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n"]}]},{"cell_type":"code","source":["# Creating the meta data file about the vecterization process\n","vectorization_metadata = {\n","    \"dataset\": \"IMDb Movie Reviews (Processed)\",\n","    \"preprocessing\": [\n","        \"Lowercased all text\",\n","        \"Tokenized into words\"\n","    ],\n","    \"vectorization_methods\": [\n","        {\n","            \"method\": \"TF-IDF\",\n","            \"parameters\": {\n","                \"max_features\": \"No limit\",\n","                \"ngram_range\": [1, 2]\n","            }\n","        },\n","        {\n","            \"method\": \"Bag of Words\",\n","            \"parameters\": {\n","                \"max_features\": \"No limit\",\n","                \"ngram_range\": [1, 1]\n","            }\n","        }\n","    ]\n","}\n","\n","# Save to JSON file\n","with open(\"vectorization_metadata.json\", \"w\") as f:\n","    json.dump(vectorization_metadata, f, indent=4)\n","\n","print(\"Metadata saved to vectorization_metadata.json!\")\n"],"metadata":{"id":"ox3NSjP7-ZrA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating the meta data file about the vecterization process\n","vectorization_metadata = {\n","    \"dataset\": \"IMDb Movie Reviews (Seperated Into Individual Text Files)\",\n","    \"preprocessing\": [\n","        {\n","            \"method\": \"Lowercased all text\",\n","            \"description\": \"Converting all text to lowercase to ensure that words are treated the same regardless of their capitalization.\"\n","        },\n","        {\n","            \"method\": \"Tokenized into words\",\n","            \"description\": \"Splitting text into individual words.\"\n","        }\n","    ],\n","    \"vectorization_methods\": [\n","        {\n","            \"method\": \"TF-IDF\",\n","            \"description\": \"TF-IDF (Term Frequency-Inverse Document Frequency) assigns weights to words based on their frequency within a document and across the entire corpus.\",\n","            \"parameters\": {\n","                \"min_df\": 1},\n","            },\n","        {\n","            \"method\": \"Bag of Words\",\n","            \"description\": \"Bag of Words represents text as a collection of words and their frequencies, ignoring grammar and word order. It creates a numerical representation of text based on the presence and count of words.\"\n","            }\n","    ]\n","}"],"metadata":{"id":"eYBwcfxF_IFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = \"/content/drive/MyDrive/DE_CW2/vectorization_metadata.json\"\n","# Save to JSON file\n","with open(file_path, \"w\") as f:\n","    json.dump(vectorization_metadata, f, indent=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GppjVUu9AOpo","executionInfo":{"status":"ok","timestamp":1733237788204,"user_tz":-330,"elapsed":510,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}},"outputId":"20fe251f-09fb-4b9b-9623-1ec02c600c0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metadata saved to vectorization_metadata.json!\n"]}]},{"cell_type":"code","source":["# Load the Excel files with\n","df = pd.read_excel(\"/content/drive/MyDrive/DE_CW2/Movie Review Sentimnet Labels.xlsx\")\n","\n","# Save to JSON\n","df.to_json(\"/content/drive/MyDrive/DE_CW2/Movie Review Sentiment Labels.json\", orient=\"records\", indent=4)"],"metadata":{"id":"dn7DlE9zoHLF","executionInfo":{"status":"ok","timestamp":1733290218690,"user_tz":-330,"elapsed":1086,"user":{"displayName":"Govindu Sathruwan","userId":"02876608951542024400"}}},"execution_count":3,"outputs":[]}]}